{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeSLSzmR-isX",
        "outputId": "8a5f4a0e-478b-4d63-f13e-07abe1794df6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycolmap\n",
            "  Downloading pycolmap-3.12.3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pycolmap) (2.0.2)\n",
            "Downloading pycolmap-3.12.3-cp311-cp311-manylinux_2_28_x86_64.whl (19.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.9/19.9 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pycolmap\n",
            "Successfully installed pycolmap-3.12.3\n",
            "Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,267 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,157 kB]\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,124 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,964 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,762 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,470 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5,163 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,572 kB]\n",
            "Fetched 31.9 MB in 3s (12.1 MB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "Collecting git+https://github.com/rahul-goel/fused-ssim/\n",
            "  Cloning https://github.com/rahul-goel/fused-ssim/ to /tmp/pip-req-build-bqtuhqvj\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/rahul-goel/fused-ssim/ /tmp/pip-req-build-bqtuhqvj\n",
            "  Resolved https://github.com/rahul-goel/fused-ssim/ to commit e81b5e05cbf5d4b4ca203b1c881e0e3f50acc354\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fused_ssim\n",
            "  Building wheel for fused_ssim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fused_ssim: filename=fused_ssim-0.0.0-cp311-cp311-linux_x86_64.whl size=2750509 sha256=7b9d6fdb591fb4b57b18ee13bc5ebe1f0c40487f1df92b708a1eb6f3e3060c7e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_upm7dk3/wheels/e5/0e/e3/03da5a017f18946399e482df664735807d031368bf471cae87\n",
            "Successfully built fused_ssim\n",
            "Installing collected packages: fused_ssim\n",
            "Successfully installed fused_ssim-0.0.0\n",
            "Mounted at /content/drive\n",
            "fatal: destination path 'LGM' already exists and is not an empty directory.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip install pycolmap\n",
        "!apt-get update\n",
        "!apt-get install -y ffmpeg\n",
        "!pip install git+https://github.com/rahul-goel/fused-ssim/ --no-build-isolation\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir(\"/content/drive/MyDrive/camera_photos/gaussian-splatting/submodules/\")\n",
        "!git clone https://huggingface.co/spaces/ashawkey/LGM\n",
        "os.system('pip install -e ./diff-gaussian-rasterization')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wE9UB3NgUnj",
        "outputId": "cc2c8a33-a0fb-4d7e-fd38-689021de099a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected model format: '.bin'\n",
            "num_cameras: 336\n",
            "num_images: 336\n",
            "num_points3D: 49554\n"
          ]
        }
      ],
      "source": [
        "# read_write_model.py\n",
        "import argparse\n",
        "import collections\n",
        "import os\n",
        "import struct\n",
        "import numpy as np\n",
        "\n",
        "CameraModel = collections.namedtuple(\n",
        "    \"CameraModel\", [\"model_id\", \"model_name\", \"num_params\"]\n",
        ")\n",
        "Camera = collections.namedtuple(\n",
        "    \"Camera\", [\"id\", \"model\", \"width\", \"height\", \"params\"]\n",
        ")\n",
        "BaseImage = collections.namedtuple(\n",
        "    \"Image\", [\"id\", \"qvec\", \"tvec\", \"camera_id\", \"name\", \"xys\", \"point3D_ids\"]\n",
        ")\n",
        "Point3D = collections.namedtuple(\n",
        "    \"Point3D\", [\"id\", \"xyz\", \"rgb\", \"error\", \"image_ids\", \"point2D_idxs\"]\n",
        ")\n",
        "\n",
        "\n",
        "class Image(BaseImage):\n",
        "    def qvec2rotmat(self):\n",
        "        return qvec2rotmat(self.qvec)\n",
        "\n",
        "\n",
        "CAMERA_MODELS = {\n",
        "    CameraModel(model_id=0, model_name=\"SIMPLE_PINHOLE\", num_params=3),\n",
        "    CameraModel(model_id=1, model_name=\"PINHOLE\", num_params=4),\n",
        "    CameraModel(model_id=2, model_name=\"SIMPLE_RADIAL\", num_params=4),\n",
        "    CameraModel(model_id=3, model_name=\"RADIAL\", num_params=5),\n",
        "    CameraModel(model_id=4, model_name=\"OPENCV\", num_params=8),\n",
        "    CameraModel(model_id=5, model_name=\"OPENCV_FISHEYE\", num_params=8),\n",
        "    CameraModel(model_id=6, model_name=\"FULL_OPENCV\", num_params=12),\n",
        "    CameraModel(model_id=7, model_name=\"FOV\", num_params=5),\n",
        "    CameraModel(model_id=8, model_name=\"SIMPLE_RADIAL_FISHEYE\", num_params=4),\n",
        "    CameraModel(model_id=9, model_name=\"RADIAL_FISHEYE\", num_params=5),\n",
        "    CameraModel(model_id=10, model_name=\"THIN_PRISM_FISHEYE\", num_params=12),\n",
        "}\n",
        "CAMERA_MODEL_IDS = dict(\n",
        "    [(camera_model.model_id, camera_model) for camera_model in CAMERA_MODELS]\n",
        ")\n",
        "CAMERA_MODEL_NAMES = dict(\n",
        "    [(camera_model.model_name, camera_model) for camera_model in CAMERA_MODELS]\n",
        ")\n",
        "\n",
        "\n",
        "def read_next_bytes(fid, num_bytes, format_char_sequence, endian_character=\"<\"):\n",
        "    \"\"\"Read and unpack the next bytes from a binary file.\n",
        "    :param fid:\n",
        "    :param num_bytes: Sum of combination of {2, 4, 8}, e.g. 2, 6, 16, 30, etc.\n",
        "    :param format_char_sequence: List of {c, e, f, d, h, H, i, I, l, L, q, Q}.\n",
        "    :param endian_character: Any of {@, =, <, >, !}\n",
        "    :return: Tuple of read and unpacked values.\n",
        "    \"\"\"\n",
        "    data = fid.read(num_bytes)\n",
        "    return struct.unpack(endian_character + format_char_sequence, data)\n",
        "\n",
        "\n",
        "def write_next_bytes(fid, data, format_char_sequence, endian_character=\"<\"):\n",
        "    \"\"\"pack and write to a binary file.\n",
        "    :param fid:\n",
        "    :param data: data to send, if multiple elements are sent at the same time,\n",
        "    they should be encapsuled either in a list or a tuple\n",
        "    :param format_char_sequence: List of {c, e, f, d, h, H, i, I, l, L, q, Q}.\n",
        "    should be the same length as the data list or tuple\n",
        "    :param endian_character: Any of {@, =, <, >, !}\n",
        "    \"\"\"\n",
        "    if isinstance(data, (list, tuple)):\n",
        "        bytes = struct.pack(endian_character + format_char_sequence, *data)\n",
        "    else:\n",
        "        bytes = struct.pack(endian_character + format_char_sequence, data)\n",
        "    fid.write(bytes)\n",
        "\n",
        "\n",
        "def read_cameras_text(path):\n",
        "    \"\"\"\n",
        "    see: src/colmap/scene/reconstruction.cc\n",
        "        void Reconstruction::WriteCamerasText(const std::string& path)\n",
        "        void Reconstruction::ReadCamerasText(const std::string& path)\n",
        "    \"\"\"\n",
        "    cameras = {}\n",
        "    with open(path, \"r\") as fid:\n",
        "        while True:\n",
        "            line = fid.readline()\n",
        "            if not line:\n",
        "                break\n",
        "            line = line.strip()\n",
        "            if len(line) > 0 and line[0] != \"#\":\n",
        "                elems = line.split()\n",
        "                camera_id = int(elems[0])\n",
        "                model = elems[1]\n",
        "                width = int(elems[2])\n",
        "                height = int(elems[3])\n",
        "                params = np.array(tuple(map(float, elems[4:])))\n",
        "                cameras[camera_id] = Camera(\n",
        "                    id=camera_id,\n",
        "                    model=model,\n",
        "                    width=width,\n",
        "                    height=height,\n",
        "                    params=params,\n",
        "                )\n",
        "    return cameras\n",
        "\n",
        "\n",
        "def read_cameras_binary(path_to_model_file):\n",
        "    cameras = {}\n",
        "    with open(path_to_model_file, \"rb\") as fid:\n",
        "        num_cameras = read_next_bytes(fid, 8, \"Q\")[0]\n",
        "        for _ in range(num_cameras):\n",
        "            camera_properties = read_next_bytes(\n",
        "                fid, num_bytes=24, format_char_sequence=\"iiQQ\"\n",
        "            )\n",
        "            camera_id = camera_properties[0]\n",
        "            model_id = camera_properties[1]\n",
        "            model_name = CAMERA_MODEL_IDS[camera_properties[1]].model_name\n",
        "            width = camera_properties[2]\n",
        "            height = camera_properties[3]\n",
        "            num_params = CAMERA_MODEL_IDS[model_id].num_params\n",
        "            params = read_next_bytes(\n",
        "                fid,\n",
        "                num_bytes=8 * num_params,\n",
        "                format_char_sequence=\"d\" * num_params,\n",
        "            )\n",
        "            cameras[camera_id] = Camera(\n",
        "                id=camera_id,\n",
        "                model=model_name,\n",
        "                width=width,\n",
        "                height=height,\n",
        "                params=np.array(params),\n",
        "            )\n",
        "        assert len(cameras) == num_cameras\n",
        "    return cameras\n",
        "\n",
        "\n",
        "def write_cameras_text(cameras, path):\n",
        "    HEADER = (\n",
        "        \"# Camera list with one line of data per camera:\\n\"\n",
        "        + \"#   CAMERA_ID, MODEL, WIDTH, HEIGHT, PARAMS[]\\n\"\n",
        "        + \"# Number of cameras: {}\\n\".format(len(cameras))\n",
        "    )\n",
        "    with open(path, \"w\") as fid:\n",
        "        fid.write(HEADER)\n",
        "        for _, cam in cameras.items():\n",
        "            to_write = [cam.id, cam.model, cam.width, cam.height, *cam.params]\n",
        "            line = \" \".join([str(elem) for elem in to_write])\n",
        "            fid.write(line + \"\\n\")\n",
        "\n",
        "\n",
        "def write_cameras_binary(cameras, path_to_model_file):\n",
        "    with open(path_to_model_file, \"wb\") as fid:\n",
        "        write_next_bytes(fid, len(cameras), \"Q\")\n",
        "        for _, cam in cameras.items():\n",
        "            model_id = CAMERA_MODEL_NAMES[cam.model].model_id\n",
        "            camera_properties = [cam.id, model_id, cam.width, cam.height]\n",
        "            write_next_bytes(fid, camera_properties, \"iiQQ\")\n",
        "            for p in cam.params:\n",
        "                write_next_bytes(fid, float(p), \"d\")\n",
        "    return cameras\n",
        "\n",
        "\n",
        "def read_images_text(path):\n",
        "    images = {}\n",
        "    with open(path, \"r\") as fid:\n",
        "        while True:\n",
        "            line = fid.readline()\n",
        "            if not line:\n",
        "                break\n",
        "            line = line.strip()\n",
        "            if len(line) > 0 and line[0] != \"#\":\n",
        "                elems = line.split()\n",
        "                image_id = int(elems[0])\n",
        "                qvec = np.array(tuple(map(float, elems[1:5])))\n",
        "                tvec = np.array(tuple(map(float, elems[5:8])))\n",
        "                camera_id = int(elems[8])\n",
        "                image_name = elems[9]\n",
        "                elems = fid.readline().split()\n",
        "                xys = np.column_stack(\n",
        "                    [\n",
        "                        tuple(map(float, elems[0::3])),\n",
        "                        tuple(map(float, elems[1::3])),\n",
        "                    ]\n",
        "                )\n",
        "                point3D_ids = np.array(tuple(map(int, elems[2::3])))\n",
        "                images[image_id] = Image(\n",
        "                    id=image_id,\n",
        "                    qvec=qvec,\n",
        "                    tvec=tvec,\n",
        "                    camera_id=camera_id,\n",
        "                    name=image_name,\n",
        "                    xys=xys,\n",
        "                    point3D_ids=point3D_ids,\n",
        "                )\n",
        "    return images\n",
        "\n",
        "\n",
        "def read_images_binary(path_to_model_file):\n",
        "    images = {}\n",
        "    with open(path_to_model_file, \"rb\") as fid:\n",
        "        num_reg_images = read_next_bytes(fid, 8, \"Q\")[0]\n",
        "        for _ in range(num_reg_images):\n",
        "            binary_image_properties = read_next_bytes(\n",
        "                fid, num_bytes=64, format_char_sequence=\"idddddddi\"\n",
        "            )\n",
        "            image_id = binary_image_properties[0]\n",
        "            qvec = np.array(binary_image_properties[1:5])\n",
        "            tvec = np.array(binary_image_properties[5:8])\n",
        "            camera_id = binary_image_properties[8]\n",
        "            binary_image_name = b\"\"\n",
        "            current_char = read_next_bytes(fid, 1, \"c\")[0]\n",
        "            while current_char != b\"\\x00\":  # look for the ASCII 0 entry\n",
        "                binary_image_name += current_char\n",
        "                current_char = read_next_bytes(fid, 1, \"c\")[0]\n",
        "            image_name = binary_image_name.decode(\"utf-8\")\n",
        "            num_points2D = read_next_bytes(\n",
        "                fid, num_bytes=8, format_char_sequence=\"Q\"\n",
        "            )[0]\n",
        "            x_y_id_s = read_next_bytes(\n",
        "                fid,\n",
        "                num_bytes=24 * num_points2D,\n",
        "                format_char_sequence=\"ddq\" * num_points2D,\n",
        "            )\n",
        "            xys = np.column_stack(\n",
        "                [\n",
        "                    tuple(map(float, x_y_id_s[0::3])),\n",
        "                    tuple(map(float, x_y_id_s[1::3])),\n",
        "                ]\n",
        "            )\n",
        "            point3D_ids = np.array(tuple(map(int, x_y_id_s[2::3])))\n",
        "            images[image_id] = Image(\n",
        "                id=image_id,\n",
        "                qvec=qvec,\n",
        "                tvec=tvec,\n",
        "                camera_id=camera_id,\n",
        "                name=image_name,\n",
        "                xys=xys,\n",
        "                point3D_ids=point3D_ids,\n",
        "            )\n",
        "    return images\n",
        "\n",
        "\n",
        "def write_images_text(images, path):\n",
        "    if len(images) == 0:\n",
        "        mean_observations = 0\n",
        "    else:\n",
        "        mean_observations = sum(\n",
        "            (len(img.point3D_ids) for _, img in images.items())\n",
        "        ) / len(images)\n",
        "    HEADER = (\n",
        "        \"# Image list with two lines of data per image:\\n\"\n",
        "        + \"#   IMAGE_ID, QW, QX, QY, QZ, TX, TY, TZ, CAMERA_ID, NAME\\n\"\n",
        "        + \"#   POINTS2D[] as (X, Y, POINT3D_ID)\\n\"\n",
        "        + \"# Number of images: {}, mean observations per image: {}\\n\".format(\n",
        "            len(images), mean_observations\n",
        "        )\n",
        "    )\n",
        "\n",
        "    with open(path, \"w\") as fid:\n",
        "        fid.write(HEADER)\n",
        "        for _, img in images.items():\n",
        "            image_header = [\n",
        "                img.id,\n",
        "                *img.qvec,\n",
        "                *img.tvec,\n",
        "                img.camera_id,\n",
        "                img.name,\n",
        "            ]\n",
        "            first_line = \" \".join(map(str, image_header))\n",
        "            fid.write(first_line + \"\\n\")\n",
        "\n",
        "            points_strings = []\n",
        "            for xy, point3D_id in zip(img.xys, img.point3D_ids):\n",
        "                points_strings.append(\" \".join(map(str, [*xy, point3D_id])))\n",
        "            fid.write(\" \".join(points_strings) + \"\\n\")\n",
        "\n",
        "\n",
        "def write_images_binary(images, path_to_model_file):\n",
        "    with open(path_to_model_file, \"wb\") as fid:\n",
        "        write_next_bytes(fid, len(images), \"Q\")\n",
        "        for _, img in images.items():\n",
        "            write_next_bytes(fid, img.id, \"i\")\n",
        "            write_next_bytes(fid, img.qvec.tolist(), \"dddd\")\n",
        "            write_next_bytes(fid, img.tvec.tolist(), \"ddd\")\n",
        "            write_next_bytes(fid, img.camera_id, \"i\")\n",
        "            for char in img.name:\n",
        "                write_next_bytes(fid, char.encode(\"utf-8\"), \"c\")\n",
        "            write_next_bytes(fid, b\"\\x00\", \"c\")\n",
        "            write_next_bytes(fid, len(img.point3D_ids), \"Q\")\n",
        "            for xy, p3d_id in zip(img.xys, img.point3D_ids):\n",
        "                write_next_bytes(fid, [*xy, p3d_id], \"ddq\")\n",
        "\n",
        "\n",
        "def read_points3D_text(path):\n",
        "    points3D = {}\n",
        "    with open(path, \"r\") as fid:\n",
        "        while True:\n",
        "            line = fid.readline()\n",
        "            if not line:\n",
        "                break\n",
        "            line = line.strip()\n",
        "            if len(line) > 0 and line[0] != \"#\":\n",
        "                elems = line.split()\n",
        "                point3D_id = int(elems[0])\n",
        "                xyz = np.array(tuple(map(float, elems[1:4])))\n",
        "                rgb = np.array(tuple(map(int, elems[4:7])))\n",
        "                error = float(elems[7])\n",
        "                image_ids = np.array(tuple(map(int, elems[8::2])))\n",
        "                point2D_idxs = np.array(tuple(map(int, elems[9::2])))\n",
        "                points3D[point3D_id] = Point3D(\n",
        "                    id=point3D_id,\n",
        "                    xyz=xyz,\n",
        "                    rgb=rgb,\n",
        "                    error=error,\n",
        "                    image_ids=image_ids,\n",
        "                    point2D_idxs=point2D_idxs,\n",
        "                )\n",
        "    return points3D\n",
        "\n",
        "\n",
        "def read_points3D_binary(path_to_model_file):\n",
        "    points3D = {}\n",
        "    with open(path_to_model_file, \"rb\") as fid:\n",
        "        num_points = read_next_bytes(fid, 8, \"Q\")[0]\n",
        "        for _ in range(num_points):\n",
        "            binary_point_line_properties = read_next_bytes(\n",
        "                fid, num_bytes=43, format_char_sequence=\"QdddBBBd\"\n",
        "            )\n",
        "            point3D_id = binary_point_line_properties[0]\n",
        "            xyz = np.array(binary_point_line_properties[1:4])\n",
        "            rgb = np.array(binary_point_line_properties[4:7])\n",
        "            error = np.array(binary_point_line_properties[7])\n",
        "            track_length = read_next_bytes(\n",
        "                fid, num_bytes=8, format_char_sequence=\"Q\"\n",
        "            )[0]\n",
        "            track_elems = read_next_bytes(\n",
        "                fid,\n",
        "                num_bytes=8 * track_length,\n",
        "                format_char_sequence=\"ii\" * track_length,\n",
        "            )\n",
        "            image_ids = np.array(tuple(map(int, track_elems[0::2])))\n",
        "            point2D_idxs = np.array(tuple(map(int, track_elems[1::2])))\n",
        "            points3D[point3D_id] = Point3D(\n",
        "                id=point3D_id,\n",
        "                xyz=xyz,\n",
        "                rgb=rgb,\n",
        "                error=error,\n",
        "                image_ids=image_ids,\n",
        "                point2D_idxs=point2D_idxs,\n",
        "            )\n",
        "    return points3D\n",
        "\n",
        "\n",
        "def write_points3D_text(points3D, path):\n",
        "    \"\"\"\n",
        "    see: src/colmap/scene/reconstruction.cc\n",
        "        void Reconstruction::ReadPoints3DText(const std::string& path)\n",
        "        void Reconstruction::WritePoints3DText(const std::string& path)\n",
        "    \"\"\"\n",
        "    if len(points3D) == 0:\n",
        "        mean_track_length = 0\n",
        "    else:\n",
        "        mean_track_length = sum(\n",
        "            (len(pt.image_ids) for _, pt in points3D.items())\n",
        "        ) / len(points3D)\n",
        "    HEADER = (\n",
        "        \"# 3D point list with one line of data per point:\\n\"\n",
        "        + \"#   POINT3D_ID, X, Y, Z, R, G, B, ERROR, TRACK[] as (IMAGE_ID, POINT2D_IDX)\\n\"\n",
        "        + \"# Number of points: {}, mean track length: {}\\n\".format(\n",
        "            len(points3D), mean_track_length\n",
        "        )\n",
        "    )\n",
        "\n",
        "    with open(path, \"w\") as fid:\n",
        "        fid.write(HEADER)\n",
        "        for _, pt in points3D.items():\n",
        "            point_header = [pt.id, *pt.xyz, *pt.rgb, pt.error]\n",
        "            fid.write(\" \".join(map(str, point_header)) + \" \")\n",
        "            track_strings = []\n",
        "            for image_id, point2D in zip(pt.image_ids, pt.point2D_idxs):\n",
        "                track_strings.append(\" \".join(map(str, [image_id, point2D])))\n",
        "            fid.write(\" \".join(track_strings) + \"\\n\")\n",
        "\n",
        "\n",
        "def write_points3D_binary(points3D, path_to_model_file):\n",
        "    \"\"\"\n",
        "    see: src/colmap/scene/reconstruction.cc\n",
        "        void Reconstruction::ReadPoints3DBinary(const std::string& path)\n",
        "        void Reconstruction::WritePoints3DBinary(const std::string& path)\n",
        "    \"\"\"\n",
        "    with open(path_to_model_file, \"wb\") as fid:\n",
        "        write_next_bytes(fid, len(points3D), \"Q\")\n",
        "        for _, pt in points3D.items():\n",
        "            write_next_bytes(fid, pt.id, \"Q\")\n",
        "            write_next_bytes(fid, pt.xyz.tolist(), \"ddd\")\n",
        "            write_next_bytes(fid, pt.rgb.tolist(), \"BBB\")\n",
        "            write_next_bytes(fid, pt.error, \"d\")\n",
        "            track_length = pt.image_ids.shape[0]\n",
        "            write_next_bytes(fid, track_length, \"Q\")\n",
        "            for image_id, point2D_id in zip(pt.image_ids, pt.point2D_idxs):\n",
        "                write_next_bytes(fid, [image_id, point2D_id], \"ii\")\n",
        "\n",
        "\n",
        "def detect_model_format(path, ext):\n",
        "    if (\n",
        "        os.path.isfile(os.path.join(path, \"cameras\" + ext))\n",
        "        and os.path.isfile(os.path.join(path, \"images\" + ext))\n",
        "        and os.path.isfile(os.path.join(path, \"points3D\" + ext))\n",
        "    ):\n",
        "        print(\"Detected model format: '\" + ext + \"'\")\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def read_model(path, ext=\"\"):\n",
        "    # try to detect the extension automatically\n",
        "    if ext == \"\":\n",
        "        if detect_model_format(path, \".bin\"):\n",
        "            ext = \".bin\"\n",
        "        elif detect_model_format(path, \".txt\"):\n",
        "            ext = \".txt\"\n",
        "        else:\n",
        "            print(\"Provide model format: '.bin' or '.txt'\")\n",
        "            return\n",
        "\n",
        "    if ext == \".txt\":\n",
        "        cameras = read_cameras_text(os.path.join(path, \"cameras\" + ext))\n",
        "        images = read_images_text(os.path.join(path, \"images\" + ext))\n",
        "        points3D = read_points3D_text(os.path.join(path, \"points3D\") + ext)\n",
        "    else:\n",
        "        cameras = read_cameras_binary(os.path.join(path, \"cameras\" + ext))\n",
        "        images = read_images_binary(os.path.join(path, \"images\" + ext))\n",
        "        points3D = read_points3D_binary(os.path.join(path, \"points3D\") + ext)\n",
        "    return cameras, images, points3D\n",
        "\n",
        "\n",
        "def write_model(cameras, images, points3D, path, ext=\".bin\"):\n",
        "    if ext == \".txt\":\n",
        "        write_cameras_text(cameras, os.path.join(path, \"cameras\" + ext))\n",
        "        write_images_text(images, os.path.join(path, \"images\" + ext))\n",
        "        write_points3D_text(points3D, os.path.join(path, \"points3D\") + ext)\n",
        "    else:\n",
        "        write_cameras_binary(cameras, os.path.join(path, \"cameras\" + ext))\n",
        "        write_images_binary(images, os.path.join(path, \"images\" + ext))\n",
        "        write_points3D_binary(points3D, os.path.join(path, \"points3D\") + ext)\n",
        "    return cameras, images, points3D\n",
        "\n",
        "\n",
        "def qvec2rotmat(qvec):\n",
        "    return np.array(\n",
        "        [\n",
        "            [\n",
        "                1 - 2 * qvec[2] ** 2 - 2 * qvec[3] ** 2,\n",
        "                2 * qvec[1] * qvec[2] - 2 * qvec[0] * qvec[3],\n",
        "                2 * qvec[3] * qvec[1] + 2 * qvec[0] * qvec[2],\n",
        "            ],\n",
        "            [\n",
        "                2 * qvec[1] * qvec[2] + 2 * qvec[0] * qvec[3],\n",
        "                1 - 2 * qvec[1] ** 2 - 2 * qvec[3] ** 2,\n",
        "                2 * qvec[2] * qvec[3] - 2 * qvec[0] * qvec[1],\n",
        "            ],\n",
        "            [\n",
        "                2 * qvec[3] * qvec[1] - 2 * qvec[0] * qvec[2],\n",
        "                2 * qvec[2] * qvec[3] + 2 * qvec[0] * qvec[1],\n",
        "                1 - 2 * qvec[1] ** 2 - 2 * qvec[2] ** 2,\n",
        "            ],\n",
        "        ]\n",
        "    )\n",
        "\n",
        "\n",
        "def rotmat2qvec(R):\n",
        "    Rxx, Ryx, Rzx, Rxy, Ryy, Rzy, Rxz, Ryz, Rzz = R.flat\n",
        "    K = (\n",
        "        np.array(\n",
        "            [\n",
        "                [Rxx - Ryy - Rzz, 0, 0, 0],\n",
        "                [Ryx + Rxy, Ryy - Rxx - Rzz, 0, 0],\n",
        "                [Rzx + Rxz, Rzy + Ryz, Rzz - Rxx - Ryy, 0],\n",
        "                [Ryz - Rzy, Rzx - Rxz, Rxy - Ryx, Rxx + Ryy + Rzz],\n",
        "            ]\n",
        "        )\n",
        "        / 3.0\n",
        "    )\n",
        "    eigvals, eigvecs = np.linalg.eigh(K)\n",
        "    qvec = eigvecs[[3, 0, 1, 2], np.argmax(eigvals)]\n",
        "    if qvec[0] < 0:\n",
        "        qvec *= -1\n",
        "    return qvec\n",
        "\n",
        "\n",
        "def add_cameras_to_dict(cameras, camera_params_list):\n",
        "    \"\"\"\n",
        "    cameras: 기존 카메라 딕셔너리\n",
        "    camera_params_list: [\n",
        "        {'id': 1, 'model': 'PINHOLE', 'width': 4032, 'height': 3024, 'params': [fx1, fy1, cx1, cy1]},\n",
        "        {'id': 2, 'model': 'PINHOLE', 'width': 4032, 'height': 3024, 'params': [fx2, fy2, cx2, cy2]},\n",
        "        ...\n",
        "    ]\n",
        "    \"\"\"\n",
        "    for cam in camera_params_list:\n",
        "        cameras[cam['id']] = Camera(\n",
        "            id=cam['id'],\n",
        "            model=cam['model'],\n",
        "            width=cam['width'],\n",
        "            height=cam['height'],\n",
        "            params=np.array(cam['params'])\n",
        "        )\n",
        "    return cameras\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description=\"Read and write COLMAP binary and text models\"\n",
        "    )\n",
        "    parser.add_argument(\"--input_model\", help=\"path to input model folder\")\n",
        "    parser.add_argument(\n",
        "        \"--input_format\",\n",
        "        choices=[\".bin\", \".txt\"],\n",
        "        help=\"input model format\",\n",
        "        default=\"\",\n",
        "    )\n",
        "    parser.add_argument(\"--output_model\", help=\"path to output model folder\")\n",
        "    parser.add_argument(\n",
        "        \"--output_format\",\n",
        "        choices=[\".bin\", \".txt\"],\n",
        "        help=\"output model format\",\n",
        "        default=\".txt\",\n",
        "    )\n",
        "    args, _ = parser.parse_known_args()\n",
        "\n",
        "    input_model_path = args.input_model if args.input_model else \"/content/drive/MyDrive/camera_photos/happy_noodles/frames/sparse/\"\n",
        "    output_model_path = args.output_model if args.output_model else \"/content/drive/MyDrive/camera_photos/happy_noodles/frames/sparse/\"\n",
        "\n",
        "    cameras, images, points3D = read_model(\n",
        "        path=input_model_path, ext=args.input_format\n",
        "    )\n",
        "\n",
        "    camera_params_list = [       # [fx1, fy1, cx1, cy1]\n",
        "        # {'id': 10, 'model': 'PINHOLE', 'width': 1209, 'height': 907, 'params': [900.32, 900.57, 604.5, 435.5]}, # 사진\n",
        "        {'id': 11, 'model': 'PINHOLE', 'width': 768, 'height': 432, 'params': [571.91, 428.94, 384., 216.]},    # 동영상 1x\n",
        "        # {'id': 12, 'model': 'PINHOLE', 'width': 768, 'height': 432, 'params': [209.44, 157.26, 384., 216.]},    # 동영상 0.5x\n",
        "    ]\n",
        "    cameras = add_cameras_to_dict(cameras, camera_params_list)\n",
        "\n",
        "    for img in images.values():\n",
        "        if img.name.startswith(\"5276\"):\n",
        "            img = img._replace(camera_id=11)\n",
        "            images[img.id] = img\n",
        "\n",
        "    print(\"num_cameras:\", len(cameras))\n",
        "    print(\"num_images:\", len(images))\n",
        "    print(\"num_points3D:\", len(points3D))\n",
        "\n",
        "    if output_model_path is not None:\n",
        "        write_model(\n",
        "            cameras,\n",
        "            images,\n",
        "            points3D,\n",
        "            path=output_model_path,\n",
        "            ext=args.output_format,\n",
        "        )\n",
        "\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJ9w7tuWIRU0"
      },
      "outputs": [],
      "source": [
        "# # dependencies for gaussian splatting\n",
        "# !pip install joblib\n",
        "# !pip install torchaudio\n",
        "# !pip install plyfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1VwM6-J1Fn8g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28968341-f5f9-43e1-fb45-ddf96ca56526"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "pycolmap SfM pipeline:   0%|          | 0/3 [00:00<?, ?step/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "실행: Feature extraction\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "pycolmap SfM pipeline:  33%|███▎      | 1/3 [12:50<25:41, 770.90s/step]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "실행: Feature matching (sequential)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "pycolmap SfM pipeline:  67%|██████▋   | 2/3 [15:51<07:03, 423.55s/step]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "실행: Incremental mapping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "pycolmap SfM pipeline: 100%|██████████| 3/3 [25:02<00:00, 500.88s/step]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델 저장...\n",
            "pycolmap SfM 완료\n",
            "Gaussian Splatting...\n",
            "Gaussian Splatting training 완료\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import pycolmap\n",
        "import subprocess\n",
        "from tqdm import tqdm\n",
        "\n",
        "colmap_path = \"colmap\"\n",
        "gpu = True\n",
        "\n",
        "def run_pycolmap_sfm(image_dir, output_dir, num_threads=8, GPU=gpu, colmap_path=\"colmap\"):\n",
        "    \"\"\"\n",
        "    pycolmap의 공식 파이프라인: feature extraction, matching, SfM을 순차적으로 실행\n",
        "    \"\"\"\n",
        "    db_path = os.path.join(output_dir, \"database.db\")\n",
        "    sparse_dir = os.path.join(output_dir, \"sparse/\")\n",
        "    dense_dir = os.path.join(output_dir, \"dense/\")\n",
        "    os.makedirs(sparse_dir, exist_ok=True)\n",
        "    os.makedirs(dense_dir, exist_ok=True)\n",
        "\n",
        "    if GPU:\n",
        "        matching_options = pycolmap.SequentialMatchingOptions(num_threads=num_threads)\n",
        "        mapper_options = pycolmap.IncrementalPipelineOptions(num_threads=num_threads)\n",
        "        steps = [\n",
        "        (\"Feature extraction\", lambda: pycolmap.extract_features(db_path, image_dir, sift_options={\"num_threads\":num_threads,\n",
        "                                                                                                   \"use_gpu\":1,\n",
        "                                                                                                   \"max_num_features\":16000,\n",
        "                                                                                                   \"estimate_affine_shape\":True,\n",
        "                                                                                                   \"domain_size_pooling\":True})),\n",
        "        # (\"Feature matching (exhaustive)\", lambda: pycolmap.match_exhaustive(db_path)),\n",
        "        (\"Feature matching (sequential)\", lambda: pycolmap.match_sequential(db_path, matching_options=matching_options)),\n",
        "        (\"Incremental mapping\", lambda: pycolmap.incremental_mapping(db_path, image_dir, sparse_dir, mapper_options)),\n",
        "    ]\n",
        "    else:\n",
        "        steps = [\n",
        "        (\"Feature extraction\", lambda: pycolmap.extract_features(db_path, image_dir)),\n",
        "        (\"Feature matching (exhaustive)\", lambda: pycolmap.match_exhaustive(db_path)),\n",
        "        # (\"Feature matching (sequential)\", lambda: pycolmap.match_sequential(db_path)),\n",
        "        (\"Incremental mapping\", lambda: pycolmap.incremental_mapping(db_path, image_dir, sparse_dir)),\n",
        "    ]\n",
        "\n",
        "    results = None\n",
        "\n",
        "    for desc, func in tqdm(steps, desc=\"pycolmap SfM pipeline\", unit=\"step\"):\n",
        "        tqdm.write(f\"실행: {desc}\")\n",
        "        if desc == \"Incremental mapping\":\n",
        "            results = func()\n",
        "        else:\n",
        "            func()\n",
        "\n",
        "    if results:\n",
        "        tqdm.write(\"모델 저장...\")\n",
        "        results[0].write(sparse_dir)        # maps[0]이 가장 큰 모델\n",
        "    tqdm.write(\"pycolmap SfM 완료\")\n",
        "\n",
        "\n",
        "def prepare_gaussian_splatting_dataset(pycolmap_sparse_dir, images_dir, output_dir):\n",
        "    os.makedirs(os.path.join(output_dir, \"images\"), exist_ok=True)\n",
        "    imgs_dir = [x for x in os.listdir(images_dir) if x.endswith(\".jpg\") or x.endswith(\".JPG\")]\n",
        "\n",
        "    os.makedirs(os.path.join(output_dir, \"sparse/\"), exist_ok=True)\n",
        "    sparse_files = [\"cameras.bin\", \"images.bin\", \"points3D.bin\"]\n",
        "\n",
        "def train_gaussian_splatting(dataset_dir, gs_code_dir):\n",
        "    tqdm.write(\"Gaussian Splatting...\")\n",
        "    subprocess.run([\n",
        "        \"python\", os.path.join(gs_code_dir, \"train.py\"),\n",
        "        \"-s\", dataset_dir\n",
        "    ])\n",
        "    tqdm.write(\"Gaussian Splatting training 완료\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    image_dir = \"/content/drive/MyDrive/camera_photos/happy_noodles/frames/images/\"  # 이미지 폴더\n",
        "    pycolmap_output_dir = \"/content/drive/MyDrive/camera_photos/happy_noodles/frames/\"\n",
        "    gs_dataset_dir = pycolmap_output_dir\n",
        "    gs_code_dir = \"/content/drive/MyDrive/camera_photos/gaussian-splatting/\"\n",
        "\n",
        "    gpu = True\n",
        "    run_pycolmap_sfm(image_dir, pycolmap_output_dir, 8, gpu, colmap_path)\n",
        "    prepare_gaussian_splatting_dataset(\n",
        "        pycolmap_sparse_dir=os.path.join(pycolmap_output_dir, \"sparse/\"),\n",
        "        images_dir=image_dir,\n",
        "        output_dir=gs_dataset_dir\n",
        "    )\n",
        "    train_gaussian_splatting(gs_dataset_dir, gs_code_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NsvwhjUAHvzU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e32af02-2b3e-470e-c90e-7b07b7be4639"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting viser\n",
            "  Downloading viser-1.0.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: imageio<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from viser) (2.37.0)\n",
            "Collecting msgspec<1.0.0,>=0.18.6 (from viser)\n",
            "  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting nodeenv<2.0.0,>=1.8.0 (from viser)\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from viser) (2.0.2)\n",
            "Requirement already satisfied: opencv-python<5.0.0,>=4.0.0.21 in /usr/local/lib/python3.11/dist-packages (from viser) (4.11.0.86)\n",
            "Requirement already satisfied: psutil<8.0.0,>=5.9.5 in /usr/local/lib/python3.11/dist-packages (from viser) (5.9.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from viser) (2.32.3)\n",
            "Requirement already satisfied: rich<15.0.0,>=13.3.3 in /usr/local/lib/python3.11/dist-packages (from viser) (13.9.4)\n",
            "Requirement already satisfied: scikit-image<1.0.0,>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from viser) (0.25.2)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.7.3 in /usr/local/lib/python3.11/dist-packages (from viser) (1.15.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from viser) (4.67.1)\n",
            "Collecting trimesh<5.0.0,>=3.21.7 (from viser)\n",
            "  Downloading trimesh-4.7.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting tyro<1.0.0,>=0.2.0 (from viser)\n",
            "  Downloading tyro-0.9.26-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: websockets<16.0.0,>=13.1 in /usr/local/lib/python3.11/dist-packages (from viser) (15.0.1)\n",
            "Collecting yourdfpy<1.0.0,>=0.0.53 (from viser)\n",
            "  Downloading yourdfpy-0.0.58-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0.0,>=2.0.0->viser) (11.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->viser) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->viser) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->viser) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->viser) (2025.7.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<15.0.0,>=13.3.3->viser) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<15.0.0,>=13.3.3->viser) (2.19.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image<1.0.0,>=0.18.0->viser) (3.5)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image<1.0.0,>=0.18.0->viser) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image<1.0.0,>=0.18.0->viser) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image<1.0.0,>=0.18.0->viser) (0.4)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro<1.0.0,>=0.2.0->viser) (0.16)\n",
            "Collecting shtab>=1.5.6 (from tyro<1.0.0,>=0.2.0->viser)\n",
            "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro<1.0.0,>=0.2.0->viser) (4.4.4)\n",
            "Requirement already satisfied: typing-extensions>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from tyro<1.0.0,>=0.2.0->viser) (4.14.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from yourdfpy<1.0.0,>=0.0.53->viser) (5.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from yourdfpy<1.0.0,>=0.0.53->viser) (1.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=13.3.3->viser) (0.1.2)\n",
            "Collecting colorlog (from trimesh[easy]>=3.11.2->yourdfpy<1.0.0,>=0.0.53->viser)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting manifold3d>=2.3.0 (from trimesh[easy]>=3.11.2->yourdfpy<1.0.0,>=0.0.53->viser)\n",
            "  Downloading manifold3d-3.2.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from trimesh[easy]>=3.11.2->yourdfpy<1.0.0,>=0.0.53->viser) (4.24.1)\n",
            "Collecting svg.path (from trimesh[easy]>=3.11.2->yourdfpy<1.0.0,>=0.0.53->viser)\n",
            "  Downloading svg_path-7.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting pycollada (from trimesh[easy]>=3.11.2->yourdfpy<1.0.0,>=0.0.53->viser)\n",
            "  Downloading pycollada-0.9.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (from trimesh[easy]>=3.11.2->yourdfpy<1.0.0,>=0.0.53->viser) (2.1.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from trimesh[easy]>=3.11.2->yourdfpy<1.0.0,>=0.0.53->viser) (3.5.0)\n",
            "Collecting rtree (from trimesh[easy]>=3.11.2->yourdfpy<1.0.0,>=0.0.53->viser)\n",
            "  Downloading rtree-1.4.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from trimesh[easy]>=3.11.2->yourdfpy<1.0.0,>=0.0.53->viser) (0.28.1)\n",
            "Collecting embreex (from trimesh[easy]>=3.11.2->yourdfpy<1.0.0,>=0.0.53->viser)\n",
            "  Downloading embreex-2.17.7.post6-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (2.9 kB)\n",
            "Collecting vhacdx (from trimesh[easy]>=3.11.2->yourdfpy<1.0.0,>=0.0.53->viser)\n",
            "  Downloading vhacdx-0.0.8.post2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting mapbox_earcut>=1.0.2 (from trimesh[easy]>=3.11.2->yourdfpy<1.0.0,>=0.0.53->viser)\n",
            "  Downloading mapbox_earcut-1.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->trimesh[easy]>=3.11.2->yourdfpy<1.0.0,>=0.0.53->viser) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->trimesh[easy]>=3.11.2->yourdfpy<1.0.0,>=0.0.53->viser) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->trimesh[easy]>=3.11.2->yourdfpy<1.0.0,>=0.0.53->viser) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->trimesh[easy]>=3.11.2->yourdfpy<1.0.0,>=0.0.53->viser) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->trimesh[easy]>=3.11.2->yourdfpy<1.0.0,>=0.0.53->viser) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->trimesh[easy]>=3.11.2->yourdfpy<1.0.0,>=0.0.53->viser) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->trimesh[easy]>=3.11.2->yourdfpy<1.0.0,>=0.0.53->viser) (0.26.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from pycollada->trimesh[easy]>=3.11.2->yourdfpy<1.0.0,>=0.0.53->viser) (2.9.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->trimesh[easy]>=3.11.2->yourdfpy<1.0.0,>=0.0.53->viser) (1.3.1)\n",
            "Downloading viser-1.0.0-py3-none-any.whl (29.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.1/29.1 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading trimesh-4.7.1-py3-none-any.whl (709 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m709.0/709.0 kB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.9.26-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.0/129.0 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yourdfpy-0.0.58-py3-none-any.whl (22 kB)\n",
            "Downloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
            "Downloading manifold3d-3.2.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mapbox_earcut-1.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.0/97.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading embreex-2.17.7.post6-cp311-cp311-manylinux_2_28_x86_64.whl (17.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.2/17.2 MB\u001b[0m \u001b[31m111.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycollada-0.9.2-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rtree-1.4.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (541 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m541.1/541.1 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading svg_path-7.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading vhacdx-0.0.8.post2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (266 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.1/266.1 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: vhacdx, trimesh, svg.path, shtab, rtree, nodeenv, msgspec, mapbox_earcut, manifold3d, embreex, colorlog, pycollada, tyro, yourdfpy, viser\n",
            "Successfully installed colorlog-6.9.0 embreex-2.17.7.post6 manifold3d-3.2.0 mapbox_earcut-1.0.3 msgspec-0.19.0 nodeenv-1.9.1 pycollada-0.9.2 rtree-1.4.0 shtab-1.7.2 svg.path-7.0 trimesh-4.7.1 tyro-0.9.26 vhacdx-0.0.8.post2 viser-1.0.0 yourdfpy-0.0.58\n"
          ]
        }
      ],
      "source": [
        "# COLMAP의 .bin 파일을 직접 읽어 3D 포인트 클라우드와 카메라 위치를 웹 기반 3D 뷰어로 시각화해줌\n",
        "!pip install viser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5Y_dxBvNAjtH"
      },
      "outputs": [],
      "source": [
        "cameras_bin = \"/content/drive/MyDrive/camera_photos/happy_noodles/frames/sparse/cameras.bin\"\n",
        "images_bin = \"/content/drive/MyDrive/camera_photos/happy_noodles/frames/sparse/images.bin\"\n",
        "points3D_bin = \"/content/drive/MyDrive/camera_photos/happy_noodles/frames/sparse/points3D.bin\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UITaW0tiBV5x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "outputId": "9ad47c79-cdd2-461e-89d4-a50dba3d7af8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "╭──────────────── \u001b[1mviser\u001b[0m ────────────────╮\n",
              "│             ╷                         │\n",
              "│   HTTP      │ http://localhost:8082   │\n",
              "│   Websocket │ ws://localhost:8082     │\n",
              "│             ╵                         │\n",
              "╰───────────────────────────────────────╯\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────── <span style=\"font-weight: bold\">viser</span> ────────────────╮\n",
              "│             ╷                         │\n",
              "│   HTTP      │ http://localhost:8082   │\n",
              "│   Websocket │ ws://localhost:8082     │\n",
              "│             ╵                         │\n",
              "╰───────────────────────────────────────╯\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Viser 서버 시작, 브라우저 localhost:8080\n",
            "서버를 중지하려면 Ctrl+C를 누르세요.\n"
          ]
        }
      ],
      "source": [
        "# 결과물인 .bin 파일들 보여주는거\n",
        "# 이거는 내 컴퓨터 로컬상에서 해야하는 거 ㅇㅇ. 코랩에서는 아무리 눌러도 안됨\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import viser\n",
        "from viser.extras.colmap import (read_cameras_binary, read_images_binary, read_points3d_binary)\n",
        "\n",
        "server = viser.ViserServer()\n",
        "\n",
        "# colmap 데이터 읽기, cameras.bin, images.bin, points3D.bin 폴더\n",
        "cameras = read_cameras_binary(cameras_bin)\n",
        "images = read_images_binary(images_bin)\n",
        "points3d = read_points3d_binary(points3D_bin)\n",
        "\n",
        "points = np.array([points3d[p_id].xyz for p_id in points3d])\n",
        "colors = np.array([points3d[p_id].rgb for p_id in points3d])\n",
        "\n",
        "server.scene.add_point_cloud(\n",
        "    name=\"/colmap/pcd\",\n",
        "    points=points,\n",
        "    colors=colors / 255.0,  # RGB 값 정규화\n",
        "    point_size=0.02,\n",
        ")\n",
        "\n",
        "for img in images.values():\n",
        "    server.scene.add_frame(\n",
        "        f\"/colmap/frame_{img.id}\",\n",
        "        wxyz=img.qvec,  # 쿼터니언, 4개: QX QW QY QZ (world -> camera)\n",
        "        position=img.tvec, # translation, 3개: TX TY TZ,        <- 7개 합쳐서 extrinsic\n",
        "        axes_length=0.1,\n",
        "        axes_radius=0.005,\n",
        "    )\n",
        "\n",
        "print(\"Viser 서버 시작, 브라우저 localhost:8080\")\n",
        "print(\"서버를 중지하려면 Ctrl+C를 누르세요.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}